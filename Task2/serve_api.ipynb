{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lrObTbyxDZny",
        "G4QBFomwDqOG",
        "STN_oICcEXU0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# FastAPI app"
      ],
      "metadata": {
        "id": "ihpHso7MEjgf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload this notebook and qlora_lora_tinyllama.zip to MyDrive\n",
        "\n",
        "## Open this notebook in colab\n",
        "\n",
        "## Mount Google drive"
      ],
      "metadata": {
        "id": "8vsrlrQmFqu7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM4p468f8Vao",
        "outputId": "4091567e-c670-468d-e0fc-38c9aa2e9499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q fastapi uvicorn[standard] pyngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps to get ngrok access key\n",
        "\n",
        "Create an ngrok account (free) → https://dashboard.ngrok.com\n",
        "\n",
        "Copy your auth token."
      ],
      "metadata": {
        "id": "RM1ZJq0sE8H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"Replace with your ngrok key\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klG_-qQr8cV0",
        "outputId": "27e82fa1-ffc0-44ac-d981-20439e01f0ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run server"
      ],
      "metadata": {
        "id": "HXfirU8nEpbD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjust path of `qlora_lora_tinyllama.zip` if needed"
      ],
      "metadata": {
        "id": "3coHp_MXGN4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o \"/content/drive/MyDrive/qlora_lora_tinyllama.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h74TKJlq_PR8",
        "outputId": "48bb0f4a-984e-40ab-90ce-2d3fa2141928"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/qlora_lora_tinyllama.zip\n",
            "   creating: content/qlora_lora_tinyllama/\n",
            "  inflating: content/qlora_lora_tinyllama/tokenizer_config.json  \n",
            "   creating: content/qlora_lora_tinyllama/checkpoint-137/\n",
            "  inflating: content/qlora_lora_tinyllama/checkpoint-137/tokenizer_config.json  \n",
            "  inflating: content/qlora_lora_tinyllama/checkpoint-137/training_args.bin  \n",
            "  inflating: content/qlora_lora_tinyllama/checkpoint-137/scheduler.pt  \n",
            "  inflating: content/qlora_lora_tinyllama/checkpoint-137/trainer_state.json  \n",
            "  inflating: content/qlora_lora_tinyllama/checkpoint-137/chat_template.jinja  \n",
            "  inflating: content/qlora_lora_tinyllama/checkpoint-137/tokenizer.model  \n",
            "  inflating: content/qlora_lora_tinyllama/checkpoint-137/scaler.pt  \n",
            "  inflating: content/qlora_lora_tinyllama/checkpoint-137/tokenizer.json  \n",
            "  inflating: content/qlora_lora_tinyllama/checkpoint-137/adapter_config.json  \n",
            "  inflating: content/qlora_lora_tinyllama/checkpoint-137/rng_state.pth  \n",
            "  inflating: content/qlora_lora_tinyllama/checkpoint-137/special_tokens_map.json  \n",
            "  inflating: content/qlora_lora_tinyllama/checkpoint-137/adapter_model.safetensors  \n",
            "  inflating: content/qlora_lora_tinyllama/checkpoint-137/optimizer.pt  \n",
            "  inflating: content/qlora_lora_tinyllama/checkpoint-137/README.md  \n",
            "  inflating: content/qlora_lora_tinyllama/chat_template.jinja  \n",
            "  inflating: content/qlora_lora_tinyllama/config.json  \n",
            "   creating: content/qlora_lora_tinyllama/runs/\n",
            "   creating: content/qlora_lora_tinyllama/runs/Dec02_14-47-54_6e7bfd5a53dc/\n",
            "  inflating: content/qlora_lora_tinyllama/runs/Dec02_14-47-54_6e7bfd5a53dc/events.out.tfevents.1764686877.6e7bfd5a53dc.187.0  \n",
            "  inflating: content/qlora_lora_tinyllama/tokenizer.model  \n",
            "  inflating: content/qlora_lora_tinyllama/model.safetensors  \n",
            "  inflating: content/qlora_lora_tinyllama/tokenizer.json  \n",
            "  inflating: content/qlora_lora_tinyllama/adapter_config.json  \n",
            "  inflating: content/qlora_lora_tinyllama/special_tokens_map.json  \n",
            "  inflating: content/qlora_lora_tinyllama/adapter_model.safetensors  \n",
            "  inflating: content/qlora_lora_tinyllama/README.md  \n",
            "  inflating: content/qlora_lora_tinyllama/generation_config.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write server file"
      ],
      "metadata": {
        "id": "-aGABxpdGbSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.py\n",
        "from fastapi import FastAPI, Depends, HTTPException, Header\n",
        "import sqlite3\n",
        "from typing import Optional\n",
        "import torch\n",
        "\n",
        "app = FastAPI(title=\"Recipe API\")\n",
        "\n",
        "DB_PATH = \"auth.db\"\n",
        "\n",
        "def get_db():\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    conn.row_factory = sqlite3.Row\n",
        "    return conn\n",
        "\n",
        "def init_db():\n",
        "    conn = get_db()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    cur.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS api_keys (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            username TEXT UNIQUE NOT NULL,\n",
        "            password TEXT NOT NULL,\n",
        "            api_key TEXT NOT NULL\n",
        "        );\n",
        "    \"\"\")\n",
        "\n",
        "    cur.execute(\"\"\"\n",
        "        INSERT OR IGNORE INTO api_keys (username, password, api_key)\n",
        "        VALUES ('admin', 'admin123', 'mysecretkey123');\n",
        "    \"\"\")\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "init_db()\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "MODEL_PATH = \"/content/content/qlora_lora_tinyllama\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, use_fast=True, legacy=False)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "model = PeftModel.from_pretrained(model, MODEL_PATH)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "def verify_api_key(x_api_key: Optional[str] = Header(None)):\n",
        "    if x_api_key is None:\n",
        "        raise HTTPException(status_code=401, detail=\"Missing API key\")\n",
        "\n",
        "    conn = get_db()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\"SELECT * FROM api_keys WHERE api_key = ?\", (x_api_key,))\n",
        "    user = cur.fetchone()\n",
        "\n",
        "    if not user:\n",
        "        raise HTTPException(status_code=401, detail=\"Invalid API key\")\n",
        "\n",
        "    return user[\"username\"]\n",
        "\n",
        "@app.post(\"/login\")\n",
        "def login(username: str, password: str):\n",
        "    conn = get_db()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"SELECT api_key FROM api_keys WHERE username = ? AND password = ?\",\n",
        "        (username, password)\n",
        "    )\n",
        "    row = cur.fetchone()\n",
        "\n",
        "    if not row:\n",
        "        raise HTTPException(status_code=401, detail=\"Invalid username or password\")\n",
        "\n",
        "    return {\"api_key\": row[\"api_key\"]}\n",
        "\n",
        "\n",
        "@app.get(\"/recipe\")\n",
        "def get_recipe(\n",
        "    ingredients: str,\n",
        "    username: str = Depends(verify_api_key)\n",
        "):\n",
        "    \"\"\"\n",
        "    Example: /recipe?ingredients=Egg,Onions\n",
        "    \"\"\"\n",
        "\n",
        "    # Build the structured cooking-assistant prompt\n",
        "    prompt = (\n",
        "        \"<<system>> You are a skilled cooking assistant.\\n\"\n",
        "        f\"<<user>> Suggest a clean, well-formatted recipe using these ingredients: {ingredients}\\n\"\n",
        "        \"<<assistant>>\"\n",
        "    )\n",
        "\n",
        "    # Tokenize\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # Generate\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=512,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    recipe = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return {\n",
        "        \"message\": \"Here is your recipe!\",\n",
        "        \"user\": username,\n",
        "        \"ingredients\": ingredients,\n",
        "        \"recipe\": recipe,\n",
        "    }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlcPoLIZ92AV",
        "outputId": "1706a48e-5a63-4155-ca61-1de81bc0a7dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run server in background"
      ],
      "metadata": {
        "id": "Amx6EAgQGhH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "process = subprocess.Popen(\n",
        "    [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
        ")"
      ],
      "metadata": {
        "id": "qfycvmjL-DYU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get publically accessible url"
      ],
      "metadata": {
        "id": "YqL1kKShGtt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note since code is running on cpu: it takes time to load model and come live"
      ],
      "metadata": {
        "id": "lrObTbyxDZny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "public_url = ngrok.connect(8000)\n",
        "public_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deEpfcPb-YKA",
        "outputId": "9d9447f5-a73f-48a8-dc47-3e6bb8bf1ea6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://vaunted-elodia-blowfly.ngrok-free.dev\" -> \"http://localhost:8000\">"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample requests"
      ],
      "metadata": {
        "id": "G4QBFomwDqOG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### you can also try with `http://localhost:8000/` if work for you"
      ],
      "metadata": {
        "id": "_zxFtxfnG5LZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace base url address with ngrok tunnel url\n",
        "!curl -X POST \"https://vaunted-elodia-blowfly.ngrok-free.dev/login?username=admin&password=admin123\""
      ],
      "metadata": {
        "id": "hs0TLStRD-uP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace base url address with ngrok tunnel url\n",
        "!curl -G \"https://vaunted-elodia-blowfly.ngrok-free.dev/recipe\" \\\n",
        "    -H \"x-api-key: mysecretkey123\" \\\n",
        "    --data-urlencode \"ingredients=Egg,Onions\""
      ],
      "metadata": {
        "id": "UhzCYKR4EN0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kill server proceess"
      ],
      "metadata": {
        "id": "STN_oICcEXU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()\n",
        "process.terminate()"
      ],
      "metadata": {
        "id": "OSB_y4J_-f0S"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}